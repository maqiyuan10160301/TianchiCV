# Datawhale 零基础入门CV赛事-Task4 模型训练与验证
## 1.划分数据集
## 1.1 欠拟合
模型过于简单，无法很好拟合真实数据

进行充分的训练或增加模型复杂度即可
## 1.2 过拟合
在训练集上表现好，在测试集上表现不好

模型完全学会了训练集上的特征，但是这些特征是有偏差的，并不是一般化的特征

**数据增强、DropOut和正则化**可以对抗过拟合
## 1.3 训练集 验证集 测试集
- 训练集

训练集用来训练模型，即确定模型的权重和偏置这些参数，通常我们称这些参数为学习参数。

- 验证集

而验证集用于模型的选择，更具体地来说，验证集并不参与学习参数的确定，也就是验证集并没有参与梯度下降的过程。验证集只是为了选择超参数，比如网络层数、网络节点数、迭代次数、学习率这些都叫超参数。

- 测试集

测试集只使用一次，即在训练完成后评价最终的模型时使用。它既不参与学习参数过程，也不参数超参数选择过程，而仅仅使用于模型的评价。 

**数据集较小时，适用传统的60/20/20的划分比例，数据集规模较大时，验证集和测试集要少于20%或10%**

## 2.构造验证集
- Hold-Out

Hold-Out 是基本的划分方法，字面意思就是“留出来一部分”，即将数据集直接按照一定比例划分。

Hold-Out 的缺点较为明显，即在验证集上计算的出来的 最后评估指标与原始数据的顺序有很大关系。为了消除特殊性，研究者提出了 “交叉验证”。

- K-Fold CV

K-Fold Cross Validation，K 折交叉验证。首先将数据集划分成 K 个大小相等的样本子集；而后依次遍历这 K 个子集，第 i ii 次(i=1,2,...,K) (i=1,2,...,K)(i=1,2,...,K) 遍历会将第 i ii 个子集作为验证集，其余所有子集作为训练集进行模型的训练与评估；最后将 K 次的评估指标的平均值 作为最终评估指标。

最常用的是 K=10. 而当 K=数据集总大小 K=数据集总大小K=数据集总大小 时，称为 留一交叉验证。即每次只将一个样本当做测试集。在 数据集总量非常大 时，留一交叉验证的开销非常大。

对于 K 折交叉验证来说，

K 值越大，意味着训练模型使用的训练集越大，则噪声所占比例越小，不容易受到噪声影响，不易产生过拟合，模型性能的方差变小；

K 值越小，意味着训练模型使用的训练集越小，噪声所占比例越大，容易受到噪声影响，易产生过拟合，模型的方差变大。

- Bootstrap

不管是 Hold-Out 还是 K-Fold CV，它们都是基于划分数据集的方法进行模型评估的。然而当 样本规模较小 时，将样本进行划分会让训练集进一步减小，这可能会影响模型训练的效果。此时可采用采样方法。

其中自助法 Bootstrap 较为常用。对于总数为 n 的数据集，进行 n 次有放回的随机抽样，得到 大小为 n 的 训练集。n 次采样的过程中，有的样本会被重复采样，有的样本没有被抽出，将这些 没有被抽出 的样本作为 验证集。

## 3.模型训练和验证
**思路如下**
- 构造训练集和验证集；
- 每轮进行训练和验证，并根据最优验证集精度保存模型
## 4.保存和加载模型
```torch.save```：保存序列化的对象到磁盘，使用了Python的pickle进行序列化，模型、张量、所有对象的字典。
```torch.load```：使用了pickle的unpacking将pickled的对象反序列化到内存中。
```torch.nn.Module.load_state_dict```：使用反序列化的state_dict加载模型的参数字典。
## 5.训练技巧
[训练技巧](http://karpathy.github.io/2019/04/25/recipe/)
- 过拟合
	* adam is safe
	adam对超参数的具有更强的适应性，可以使学习率为3e-4
	* complexify only one at a time
	每次调整一个参数
	* do not trust learning rate decay defaults
	不要使用默认学习率
	* ……
